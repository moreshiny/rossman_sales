{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the model\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from models import define_pipelines\n",
    "from models import single_run\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting folders and initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA = 'data/train.csv'\n",
    "HOLDOUT_DATA = 'data/holdout.csv'\n",
    "STORE_DATA = 'data/store.csv'\n",
    "TEST_DATA = '' # input the path of the test data file here\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "CORES = -1\n",
    "\n",
    "try:\n",
    "    df_test = pd.read_csv(TEST_DATA)\n",
    "except FileNotFoundError:\n",
    "    print('Test data file not found, using holdout as validation set')\n",
    "    df_test = pd.read_csv(HOLDOUT_DATA)\n",
    "    df_train = pd.read_csv(TRAINING_DATA)\n",
    "else:\n",
    "    print('Test data loaded, using full training data for model training')\n",
    "    df_train = pd.concat([\n",
    "        pd.read_csv(TRAINING_DATA),\n",
    "        pd.read_csv(HOLDOUT_DATA)\n",
    "    ])\n",
    "finally:\n",
    "    df_store = pd.read_csv(STORE_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get unclean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(train, store):\n",
    "        \n",
    "    \"\"\" Takes two dataframes, creates two copies drop the \n",
    "    customers axis drop the nan for sale and stores make sure \n",
    "    the store columns are of the same type. inner merge on the column store.  \n",
    "    \"\"\"\n",
    "    train_copy = train.copy()\n",
    "    store_copy = store.copy()\n",
    "    train_copy = train_copy.drop(columns = ['Customers'])\n",
    "    train_copy = train_copy.dropna(axis = 0, how = 'any', subset = ['Sales', 'Store'])\n",
    "    train_copy['Store'] = train_copy['Store'].astype(int)\n",
    "    store_copy['Store'] = store_copy['Store'].astype(int)\n",
    "    df_p = pd.merge(train_copy, store_copy, how = 'inner', on = 'Store')\n",
    "\n",
    "    return df_p\n",
    "    \n",
    "df_p = merge_data(df_train, df_store)\n",
    "\n",
    "dropped_columns_n = ['CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear',\\\n",
    "                   'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
    "df_p1 = df_p.drop(columns = dropped_columns_n)\n",
    "\n",
    "# Estimate day-month-year etc\n",
    "\n",
    "df_unclean = df_p1.copy()\n",
    "df_unclean['Date'] = pd.to_datetime(df_unclean['Date'])    \n",
    "df_unclean['day'] = df_unclean['Date'].dt.day\n",
    "df_unclean['month'] = df_unclean['Date'].dt.month\n",
    "df_unclean['year'] = df_unclean['Date'].dt.year\n",
    "df_unclean['weekday_name'] = df_unclean['Date'].dt.day_name()\n",
    "df_unclean['weekday'] = df_unclean['Date'].apply(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data & run model to get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns='Sales')\n",
    "y_train = df_train.loc[:, 'Sales']\n",
    "X_val = df_test.drop(columns='Sales')\n",
    "y_val = df_test.loc[:, 'Sales']\n",
    "\n",
    "\n",
    "from data_cleaning import DataCleaning\n",
    "\n",
    "cleaning_settings = dict(\n",
    "    hot_encoded_columns=[\n",
    "        'StateHoliday',\n",
    "        'Assortment',\n",
    "        'SchoolHoliday',\n",
    "    ],\n",
    "    dropped_columns=[\n",
    "        'Store',\n",
    "        'CompetitionOpenSinceMonth',\n",
    "        'CompetitionOpenSinceYear',\n",
    "        'Promo2SinceWeek',\n",
    "        'Promo2SinceYear',\n",
    "        'PromoInterval',\n",
    "        'Date',\n",
    "        'Open',\n",
    "        'StoreType',\n",
    "    ],\n",
    "    filled_in_median=[\n",
    "        'CompetitionDistance',\n",
    "    ],\n",
    "    filled_in_mode=[\n",
    "        'Promo',\n",
    "    ],\n",
    "    target=[\n",
    "        'Sales',\n",
    "    ],\n",
    ")\n",
    "\n",
    "cleaning = DataCleaning(\n",
    "    store=df_store,\n",
    "    hot_encoded_columns=cleaning_settings['hot_encoded_columns'],\n",
    "    dropped_columns=cleaning_settings['dropped_columns'],\n",
    "    filled_in_median=cleaning_settings['filled_in_median'],\n",
    "    filled_in_mode=cleaning_settings['filled_in_mode'],\n",
    "    target=cleaning_settings['target'],\n",
    ")\n",
    "\n",
    "X_train_clean, y_train_clean =\\\n",
    "    cleaning.cleaning(X_train, y_train, training=True)\n",
    "X_val_clean, y_val_clean =\\\n",
    "    cleaning.cleaning(X_val, y_val, training=False)\n",
    "\n",
    "xg_settings = dict(\n",
    "    n_estimators=500,\n",
    "    max_depth=3 ,\n",
    "    learning_rate=0.2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=CORES,\n",
    ")\n",
    "\n",
    "pipes = define_pipelines(xg_settings)\n",
    "X_train, y_train, X_val, y_val, training_metrics, validation_metrics = \\\n",
    "            single_run(pipes, X_train_clean, y_train_clean,\n",
    "                               X_val_clean, y_val_clean, X_train, X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get clean train data, test data & concatenate predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: adjust cleaning so that we can run cleaning of train \n",
    "# data even if I don't drop \"Store\". Now we get an error so commented these lines\n",
    "\n",
    "# Run cleaning again but now keep some features that were previously OHE or dropped\n",
    "\n",
    "X_train = df_train.drop(columns='Sales')\n",
    "y_train = df_train.loc[:, 'Sales']\n",
    "X_val = df_test.drop(columns='Sales')\n",
    "y_val = df_test.loc[:, 'Sales']\n",
    "\n",
    "cleaning_settings = dict(\n",
    "    hot_encoded_columns=[],\n",
    "    dropped_columns=[\n",
    "        \"CompetitionOpenSinceMonth\",\n",
    "        \"CompetitionOpenSinceYear\",\n",
    "        \"Promo2SinceWeek\",\n",
    "        \"Promo2SinceYear\",\n",
    "        \"PromoInterval\",\n",
    "    ],\n",
    "    filled_in_median=[\n",
    "        \"CompetitionDistance\",\n",
    "    ],\n",
    "    filled_in_mode=[\n",
    "        \"Promo\",\n",
    "    ],\n",
    "    target=[\n",
    "        \"Sales\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "cleaning = DataCleaning(\n",
    "    store=df_store,\n",
    "    hot_encoded_columns=cleaning_settings[\"hot_encoded_columns\"],\n",
    "    dropped_columns=cleaning_settings[\"dropped_columns\"],\n",
    "    filled_in_median=cleaning_settings[\"filled_in_median\"],\n",
    "    filled_in_mode=cleaning_settings[\"filled_in_mode\"],\n",
    "    target=cleaning_settings[\"target\"],\n",
    ")\n",
    "\n",
    "X_train_clean, y_train_clean =\\\n",
    "    cleaning.cleaning(X_train, y_train, training=True)\n",
    "X_val_clean, y_val_clean =\\\n",
    "    cleaning.cleaning(X_val, y_val, training=False)\n",
    "\n",
    "\n",
    "# Concatenate features and target in test(validation) test\n",
    "\n",
    "#df_train_clean = pd.concat([X_train_clean, y_train_clean], axis=1)\n",
    "df_val_clean = pd.concat([X_val_clean, y_val_clean], axis=1)\n",
    "\n",
    "def format_datetime(df:dict) -> dict:\n",
    "    \"\"\" Extracts day,month, day, weekday from Datetime\n",
    "    \"\"\"\n",
    "    # Create day, month, year from Datetime\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    df[\"day\"] = df[\"Date\"].dt.day\n",
    "    df[\"month\"] = df[\"Date\"].dt.month\n",
    "    df[\"year\"] = df[\"Date\"].dt.year\n",
    "    df[\"weekday\"] = df[\"Date\"].apply(lambda x: x.weekday())\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#df_train_clean = format_datetime(df_train_clean)\n",
    "df_val_clean = format_datetime(df_val_clean)\n",
    "\n",
    "# Concatenate test data with predictions\n",
    "iModel = 0  # index in metrics dict . 1 for RandomForestRegressor, 0 for XGBRegressor\n",
    "df_val_clean = pd.concat(\n",
    "    [\n",
    "        df_val_clean,\n",
    "        pd.DataFrame(\n",
    "            validation_metrics[iModel][\"prediction\"],\n",
    "            columns=[\"Prediction\"],\n",
    "            index=df_val_clean.index,\n",
    "        ),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Add absolute error\n",
    "df_val_clean[\"abserror\"] = np.abs(df_val_clean[\"Prediction\"] - df_val_clean[\"Sales\"])\n",
    "\n",
    "# Add error quartiles rank\n",
    "df_val_clean[\"ErrorQuaritile\"] = pd.qcut(\n",
    "    df_val_clean[\"abserror\"], 4, labels=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
    ")\n",
    "\n",
    "# Replace category codes with meaningfull names in StateHoliday\n",
    "dict_stateholiday_rename = {\n",
    "    \"a\": \"publicHoliday\",\n",
    "    \"b\": \"Easter\",\n",
    "    \"c\": \"Christmas\",\n",
    "    \"no\": \"No StateHoliday\",\n",
    "}\n",
    "df_val_clean[\"StateHoliday\"] = df_val_clean[[\"StateHoliday\"]].replace(dict_stateholiday_rename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots for unclean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales Distribution\n",
    "\n",
    "def groupstore(df, storetype:str):\n",
    "    \"\"\" Get dataframe with avgSales and CompetitionDistance grouped by Store\"\"\"\n",
    "    df = pd.DataFrame(df\\\n",
    "                    .query(f\"StoreType=='{storetype}'\")\\\n",
    "                    .groupby([\"Store\"])[\"Sales\", \"CompetitionDistance\"]\\\n",
    "                    .mean())\\\n",
    "                    .assign(StoreType=storetype)\n",
    "    return df   \n",
    "\n",
    "unique_storetypes = df_unclean[\"StoreType\"].unique()\n",
    "\n",
    "df_unclean_grpstore= pd.concat(\n",
    "    [groupstore(df_unclean, storetype) \\\n",
    "     for storetype in unique_storetypes], axis=0\n",
    ")\n",
    "\n",
    "df_unclean_grpstore\n",
    "\n",
    "Image(px.histogram(\n",
    "    df_unclean_grpstore,\n",
    "    x=\"Sales\",\n",
    "    marginal=\"box\",\n",
    "    nbins=40,\n",
    "    width=950,\n",
    "    height=500,\n",
    "    title='Sales Distribution').to_image(format='png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sales per Weekday\n",
    "Image(px.box(\n",
    "    df_unclean,\n",
    "    x=\"weekday\",\n",
    "    y=\"Sales\",\n",
    "    color=\"weekday\",\n",
    "    width=950,\n",
    "    height=600,\n",
    "    title='Sales per Weekday',\n",
    ").to_image(format='png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  # Sales per Weekday\n",
    "Image(px.box(\n",
    "    df_unclean,\n",
    "    x=\"weekday\",\n",
    "    y=\"Sales\",\n",
    "    color=\"weekday\",\n",
    "    facet_col=\"StoreType\",\n",
    "    width=950,\n",
    "    height=600,\n",
    "    title='Sales per Weekday',\n",
    "    category_orders={\"StoreType\": [\"a\", \"b\", \"c\", \"d\"], },\n",
    ").to_image(format='png'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sales per StoreType per Assortment\n",
    "Image(px.box(\n",
    "    df_unclean,\n",
    "    x=\"StoreType\",\n",
    "    y=\"Sales\",\n",
    "    color=\"Assortment\",\n",
    "    width=800,\n",
    "    height=500,\n",
    "    category_orders={\"StoreType\": [\"a\", \"b\", \"c\", \"d\"],\n",
    "                    \"Assortment\": [\"a\", \"b\", \"c\"]},\n",
    "    title=\"Sales per StoreType per Assortment\").to_image(format='png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Plots to inspect clean data using df_train_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots to inspect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract & Plot Feature Importances from metrics dict\n",
    "\n",
    "def df_feat_imp_model(iModel, metrics):\n",
    "    \"\"\"Returns DataFrame with 3 features: FeaturesName, Importance and ModelType\"\"\"\n",
    "\n",
    "    feat_importance = metrics[iModel][\"feat_importance\"]\n",
    "    df_feat_imp = pd.DataFrame([feat[0] for feat in feat_importance], columns=[\"Feature\"])\n",
    "    df_feat_imp[\"Importance\"] = [feat[1] for feat in feat_importance]\n",
    "    df_feat_imp.sort_values(\"Importance\", ascending=False, inplace=True)\n",
    "    df_feat_imp[\"Model\"] = validation_metrics[iModel][\"model\"].__name__\n",
    "    \n",
    "    return df_feat_imp\n",
    "\n",
    "df_feat_imp_vstack = pd.concat([df_feat_imp_model(iModel, validation_metrics)\\\n",
    "                               for iModel in range(len(validation_metrics))],\n",
    "                              axis=0)\n",
    "\n",
    "fig3 = px.bar(\n",
    "    data_frame=df_feat_imp_vstack,\n",
    "    x='Importance',\n",
    "    y='Feature',\n",
    "    width=600,\n",
    "    height=900,\n",
    "    orientation=\"h\",\n",
    "    title= \"Feature Importances\",\n",
    "    #animation_frame=\"Model\", \n",
    ")\n",
    "\n",
    "fig3.update_layout(yaxis={'categoryorder':'total ascending'})\n",
    "\n",
    "Image(fig3.to_image(format='png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-series of Sales : Target vs. Prediction\n",
    "df_n = pd.DataFrame(df_val_clean\\\n",
    "                .groupby([\"Date\"])[\"Sales\", \"Prediction\"]\\\n",
    "                .mean())\n",
    "df_n\n",
    "\n",
    "df_targ = df_n[[\"Sales\"]]\n",
    "df_targ[\"Y_type\"] = \"Target\"\n",
    "\n",
    "df_pred = df_n[[\"Prediction\"]]\n",
    "df_pred = df_pred.rename(columns={\"Prediction\" : \"Sales\"})\n",
    "df_pred[\"Y_type\"] = \"Prediction\"\n",
    "\n",
    "df_date = pd.concat([df_targ, df_pred], axis=0)\n",
    "df_date = df_date.reset_index()\n",
    "df_date[\"Date\"] = pd.to_datetime(df_date['Date'])\n",
    "weekday = df_date[\"Date\"].dt.weekday\n",
    "\n",
    "Image(px.scatter(\n",
    "    df_date,\n",
    "    x=\"Date\", \n",
    "    y=\"Sales\",\n",
    "    color=\"Y_type\",\n",
    "    hover_data= [weekday],\n",
    "    width=950,\n",
    "    height=500,\n",
    "    title='Sales over time: Target vs. Prediction')\\\n",
    "    .update_traces(mode='lines+markers').to_image(format='png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-series of Sales for every Store Type\n",
    "\n",
    "def groupdate_sales_storetype(df, storetype:str):\n",
    "    \"\"\" Get dataframe with avgSales and StoreType grouped by Date \"\"\"\n",
    "    df_n = pd.DataFrame(df\\\n",
    "                    .query(f\"StoreType=='{storetype}'\")\\\n",
    "                    .groupby([\"Date\"])[\"Sales\", \"Prediction\"]\\\n",
    "                    .mean())\\\n",
    "                    .assign(StoreType=storetype)\n",
    "    return df_n   \n",
    "\n",
    "# a. For each StoreType : Get dataframe with avgSales and StoreType grouped by Date\"\"\"\n",
    "# b. Concatenate across rows \n",
    "\n",
    "unique_storetypes = df_val_clean[\"StoreType\"].unique()\n",
    "\n",
    "df_grpday_sort = pd.concat(\n",
    "    [groupdate_sales_storetype(df_val_clean, storetype) \\\n",
    "     for storetype in unique_storetypes], axis=0\n",
    ")\n",
    "\n",
    "\n",
    "df_targ1 = df_grpday_sort[[\"Sales\" , \"StoreType\"]]\n",
    "df_targ1[\"Y_type\"] = \"Target\"\n",
    "\n",
    "df_pred1 = df_grpday_sort[[\"Prediction\" , \"StoreType\"]]\n",
    "df_pred1 = df_pred1.rename(columns={\"Prediction\" : \"Sales\"})\n",
    "df_pred1[\"Y_type\"] = \"Prediction\"\n",
    "\n",
    "df_date1 = pd.concat([df_targ1, df_pred1], axis=0)\n",
    "\n",
    "df_date1 = df_date1.reset_index()\n",
    "df_date1\n",
    "\n",
    "weekday1 = df_date1[\"Date\"].dt.weekday\n",
    "\n",
    "# Time-series of Sales for every Store Type\n",
    "Image(px.scatter(\n",
    "    df_date1,\n",
    "    x=\"Date\", \n",
    "    y=\"Sales\",\n",
    "    color=\"Y_type\",\n",
    "    facet_row=\"StoreType\",\n",
    "    hover_data=[weekday1],\n",
    "    width=950,\n",
    "    height=900,\n",
    "    title='Sales over time: Target vs. Prediction per StoryType')\\\n",
    "    .update_traces(mode='lines+markers').to_image(format='png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error per Weekday\n",
    "Image(px.box(\n",
    "    df_val_clean,\n",
    "    x=\"weekday\",\n",
    "    y=\"abserror\",\n",
    "    color=\"weekday\",\n",
    "    width=950,\n",
    "    height=600,\n",
    "    category_orders={\"StoreType\": [\"a\", \"b\", \"c\", \"d\"]},\n",
    "    points=False,\n",
    "    title='Error per Weekday').to_image(format='png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error per StoreType\n",
    "Image(px.box(\n",
    "    df_val_clean,\n",
    "    x=\"StoreType\",\n",
    "    y=\"abserror\",\n",
    "    color=\"StoreType\",\n",
    "    width=600,\n",
    "    height=500,\n",
    "    category_orders={\"StoreType\": [\"a\", \"b\", \"c\", \"d\"]},\n",
    "    points=False,\n",
    "    title='Error per StoreType').to_image(format='png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Error per StateHoliday'\n",
    "Image(px.box(\n",
    "    df_val_clean,\n",
    "    x=\"StateHoliday\",\n",
    "    y=\"abserror\",\n",
    "    color=\"StateHoliday\",\n",
    "    width=750,\n",
    "    height=500,\n",
    "    points=False,\n",
    "    title='Error per StateHoliday').to_image(format='png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relation of Errors with Sales\n",
    "\n",
    "def groupstore(df, storetype:str):\n",
    "    \"\"\" Get dataframe with avgError and CompetitionDistance grouped by Store\"\"\"\n",
    "    df_n = pd.DataFrame(df\\\n",
    "                    .query(f\"StoreType=='{storetype}'\")\\\n",
    "                    .groupby([\"Store\"])[\"Sales\", \"abserror\", \"CompetitionDistance\"]\\\n",
    "                    .mean())\\\n",
    "                    .assign(StoreType=storetype)\n",
    "    return df_n   \n",
    "\n",
    "unique_storetypes = df_val_clean[\"StoreType\"].unique()\n",
    "\n",
    "df_val_grpstore= pd.concat(\n",
    "    [groupstore(df_val_clean, storetype) \\\n",
    "     for storetype in unique_storetypes], axis=0\n",
    ")\n",
    "\n",
    "df_val_grpstore\n",
    "\n",
    "Image(px.scatter(\n",
    "    df_val_grpstore,\n",
    "    x=\"Sales\", \n",
    "    y=\"abserror\",\n",
    "    color=\"StoreType\",\n",
    "    trendline=\"ols\",\n",
    "    marginal_y=\"box\",\n",
    "    marginal_x=\"box\",\n",
    "    category_orders={\"StoreType\": [\"a\", \"b\", \"c\", \"d\"]},\n",
    "    width=600,\n",
    "    height=600,\n",
    "    title='Absolute Error ~ Sales').to_image(format='png'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1d64d094c40fbdcdcf034bf96f8f5b6208019ae672f08a55f3d338f9d1f5e3a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('dsr-mini-competition': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
